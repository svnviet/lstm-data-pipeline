{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Path depends on where you uploaded\n",
        "model = keras.models.load_model(\"/content/model.keras\")\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "q7RYbo3dFX83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "FEATURE_COLS = [\n",
        "    # --- Base OHLCV ---\n",
        "    \"Open\", \"High\", \"Low\", \"Close\", \"TickVolume\",\n",
        "\n",
        "    # --- Returns ---\n",
        "    \"Close_ret\", \"Open_ret\", \"High_ret\", \"Low_ret\",\n",
        "\n",
        "    # --- Volatility ---\n",
        "    \"Range\",\n",
        "\n",
        "    # --- Time features ---\n",
        "    \"minute_of_day\", \"slot5\", \"slot5_sin\", \"slot5_cos\",\n",
        "    \"minutes_from_open\", \"minutes_to_close\", \"percent_session_elapsed\",\n",
        "    \"is_open\", \"is_close\",\n",
        "\n",
        "    # --- Day of week ---\n",
        "    \"day_of_week\", \"dow_sin\", \"dow_cos\", \"is_monday\", \"is_friday\",\n",
        "\n",
        "    # --- Technical indicators ---\n",
        "    \"SMA10\", \"SMA20\", \"EMA10\", \"VWAP\",\n",
        "    \"RSI14\", \"MACD\", \"MACD_signal\", \"MACD_diff\",\n",
        "    \"Bollinger_high\", \"Bollinger_low\", \"Bollinger_mavg\",\n",
        "    \"ATR14\"\n",
        "]\n",
        "\n",
        "TARGET_COLS = [\n",
        "    \"Open\", \"High\", \"Low\", \"Close\", \"TickVolume\"\n",
        "]\n",
        "\n",
        "MODEL_PATH = \"artifacts_saved\""
      ],
      "metadata": {
        "id": "1zaAL73sLegU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "def load_model_predict():\n",
        "    \"\"\"\n",
        "    Load artifacts and run future prediction on a new CSV.\n",
        "    \"\"\"\n",
        "    FUTURE_STEPS = 30\n",
        "    ART_NAME = \"artifacts_20250907\"\n",
        "    ART_DIR = \"/content\"  # adjust as needed\n",
        "\n",
        "    # 1) Load model & scalers (FIX: .keras + Keras 3 loader)\n",
        "    model = keras.models.load_model(\"/content/model.keras\")\n",
        "    x_scaler = joblib.load(os.path.join(ART_DIR, \"x_scaler.joblib\"))\n",
        "    y_scaler = joblib.load(os.path.join(ART_DIR, \"y_scaler.joblib\"))\n",
        "\n",
        "    # 2) Load metadata\n",
        "    with open(os.path.join(ART_DIR, \"meta.json\"), \"r\") as f:\n",
        "        meta = json.load(f)\n",
        "    feature_cols = meta[\"feature_cols\"]\n",
        "    target_cols = meta[\"target_cols\"]\n",
        "    window_size = int(meta[\"window_size\"])\n",
        "\n",
        "    # 3) Build predictor\n",
        "    predictor = Predictor(\n",
        "        model=model,\n",
        "        feature_cols=feature_cols,\n",
        "        target_cols=target_cols,\n",
        "        window_size=window_size,\n",
        "        x_scaler=x_scaler,\n",
        "        y_scaler=y_scaler,\n",
        "    )\n",
        "\n",
        "    # 4) Load & preprocess new data (FIX: keep preprocessing consistent)\n",
        "    cp = CsvPreprocessor()\n",
        "    df_new = cp.preprocess(cp.load(\"/content/xauusd_M1_exness_2025-08-01.csv\"))\n",
        "\n",
        "    # 5) Predict future\n",
        "    future_df = predictor.predict_future(df_new, steps=FUTURE_STEPS)\n",
        "\n",
        "    # 6) Save\n",
        "    future_df.to_csv(f\"future_predictions_{ART_NAME}.csv\", index=False)\n",
        "    print(\"Predictions saved to future_predictions.csv\")\n",
        "\n",
        "load_model_predict()\n"
      ],
      "metadata": {
        "id": "aYB8zJ4AHWQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta"
      ],
      "metadata": {
        "id": "AXN0cbdwIuMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ta\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict, Any, Optional\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class SplitConfig:\n",
        "    window_size: int = 60\n",
        "    ratios: Tuple[float, float, float] = (0.7, 0.2, 0.1)  # train, test, val\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TrainConfig:\n",
        "    epochs: int = 100\n",
        "    batch_size: int = 32\n",
        "    verbose: int = 1\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ScalerBundle:\n",
        "    x_scaler: Any\n",
        "    y_scaler: Any\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class DatasetSplit:\n",
        "    X_train: np.ndarray\n",
        "    y_train: np.ndarray\n",
        "    z_train: np.ndarray\n",
        "    idx_train: np.ndarray\n",
        "\n",
        "    X_test: np.ndarray\n",
        "    y_test: np.ndarray\n",
        "    z_test: np.ndarray\n",
        "    idx_test: np.ndarray\n",
        "\n",
        "    X_val: np.ndarray\n",
        "    y_val: np.ndarray\n",
        "    z_val: np.ndarray\n",
        "    idx_val: np.ndarray\n",
        "\n",
        "    feature_cols: Tuple[str, ...]\n",
        "    target_cols: Tuple[str, ...]\n",
        "    window_size: int\n",
        "    scalers: ScalerBundle\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TrainReport:\n",
        "    test_loss_scaled_mse: float\n",
        "    mape_per_target: Dict[str, float]\n",
        "    accuracy_per_target: Dict[str, float]\n",
        "    history: Optional[Dict[str, list]] = None\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, model, feature_cols: Sequence[str], target_cols: Sequence[str],\n",
        "                 window_size: int, x_scaler, y_scaler):\n",
        "        self.model = model\n",
        "        self.feature_cols = list(feature_cols)   # FIX: use list\n",
        "        self.target_cols = list(target_cols)     # FIX: use list\n",
        "        self.window_size = int(window_size)\n",
        "        self.x_scaler = x_scaler\n",
        "        self.y_scaler = y_scaler\n",
        "\n",
        "\n",
        "    # --- Helper: add engineered features automatically ---\n",
        "    def _add_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Add engineered features (returns, volatility, time, day-of-week, technicals).\"\"\"\n",
        "        df = df.copy()\n",
        "\n",
        "        # --- Returns ---\n",
        "        for col in [\"Close\", \"Open\", \"High\", \"Low\"]:\n",
        "            if f\"{col}_ret\" not in df.columns:\n",
        "                df[f\"{col}_ret\"] = df[col].pct_change()\n",
        "\n",
        "        # --- Volatility (Range) ---\n",
        "        if \"Range\" not in df.columns:\n",
        "            df[\"Range\"] = df[\"High\"] - df[\"Low\"]\n",
        "\n",
        "        # --- Time features ---\n",
        "        if \"minute_of_day\" not in df.columns:\n",
        "            df[\"minute_of_day\"] = df[\"Time\"].dt.hour * 60 + df[\"Time\"].dt.minute\n",
        "        if \"slot5\" not in df.columns:\n",
        "            df[\"slot5\"] = df[\"minute_of_day\"] // 5\n",
        "            df[\"slot5_sin\"] = np.sin(2 * np.pi * df[\"slot5\"] / 288)\n",
        "            df[\"slot5_cos\"] = np.cos(2 * np.pi * df[\"slot5\"] / 288)\n",
        "\n",
        "        # Session boundaries (UTC 01:05 → 23:54)\n",
        "        session_open, session_close = 65, 1434\n",
        "        df[\"minutes_from_open\"] = df[\"minute_of_day\"] - session_open\n",
        "        df[\"minutes_to_close\"] = session_close - df[\"minute_of_day\"]\n",
        "        df[\"percent_session_elapsed\"] = (\n",
        "            df[\"minutes_from_open\"] / (session_close - session_open)\n",
        "        ).clip(0, 1)\n",
        "\n",
        "        # Flags\n",
        "        df[\"is_open\"] = (df[\"minute_of_day\"] == session_open).astype(int)\n",
        "        df[\"is_close\"] = (df[\"minute_of_day\"] == session_close).astype(int)\n",
        "\n",
        "        # --- Day-of-week features ---\n",
        "        df[\"day_of_week\"] = df[\"Time\"].dt.dayofweek\n",
        "        df[\"dow_sin\"] = np.sin(2 * np.pi * df[\"day_of_week\"] / 5)\n",
        "        df[\"dow_cos\"] = np.cos(2 * np.pi * df[\"day_of_week\"] / 5)\n",
        "        df[\"is_monday\"] = (df[\"day_of_week\"] == 0).astype(int)\n",
        "        df[\"is_friday\"] = (df[\"day_of_week\"] == 4).astype(int)\n",
        "\n",
        "        # --- Technical Indicators ---\n",
        "        if \"SMA10\" not in df.columns:\n",
        "            df[\"SMA10\"] = df[\"Close\"].rolling(10).mean()\n",
        "        if \"SMA20\" not in df.columns:\n",
        "            df[\"SMA20\"] = df[\"Close\"].rolling(20).mean()\n",
        "        if \"EMA10\" not in df.columns:\n",
        "            df[\"EMA10\"] = df[\"Close\"].ewm(span=10, adjust=False).mean()\n",
        "        if \"VWAP\" not in df.columns:\n",
        "            df[\"VWAP\"] = (df[\"Close\"] * df[\"TickVolume\"]).cumsum() / df[\"TickVolume\"].cumsum()\n",
        "\n",
        "        if \"RSI14\" not in df.columns:\n",
        "            df[\"RSI14\"] = ta.momentum.RSIIndicator(df[\"Close\"], window=14).rsi()\n",
        "\n",
        "        if \"MACD\" not in df.columns:\n",
        "            macd = ta.trend.MACD(close=df[\"Close\"])\n",
        "            df[\"MACD\"] = macd.macd()\n",
        "            df[\"MACD_signal\"] = macd.macd_signal()\n",
        "            df[\"MACD_diff\"] = macd.macd_diff()\n",
        "\n",
        "        if \"Bollinger_high\" not in df.columns:\n",
        "            boll = ta.volatility.BollingerBands(close=df[\"Close\"], window=20, window_dev=2)\n",
        "            df[\"Bollinger_high\"] = boll.bollinger_hband()\n",
        "            df[\"Bollinger_low\"] = boll.bollinger_lband()\n",
        "            df[\"Bollinger_mavg\"] = boll.bollinger_mavg()\n",
        "\n",
        "        if \"ATR14\" not in df.columns:\n",
        "            atr = ta.volatility.AverageTrueRange(\n",
        "                high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], window=14\n",
        "            )\n",
        "            df[\"ATR14\"] = atr.average_true_range()\n",
        "\n",
        "        # Drop NaNs introduced by indicators\n",
        "        return df.dropna()\n",
        "\n",
        "    # --- Helper: convert to sliding windows ---\n",
        "    def _to_windows(self, scaled_X: np.ndarray) -> np.ndarray:\n",
        "        w = self.window_size\n",
        "        N = scaled_X.shape[0]\n",
        "        if N <= w:\n",
        "            raise ValueError(f\"Need N > window_size. Got N={N}, window_size={w}\")\n",
        "        M = N - w\n",
        "        return np.stack([scaled_X[i:i + w, :] for i in range(M)], axis=0)\n",
        "\n",
        "    def predict_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        df = self._add_features(df)\n",
        "\n",
        "        for c in self.feature_cols:\n",
        "            if c not in df.columns:\n",
        "                raise KeyError(f\"Missing feature '{c}' in new dataframe (expected {c})\")\n",
        "\n",
        "        raw_X = df[list(self.feature_cols)].to_numpy(dtype=float)\n",
        "        scaled_X = self.x_scaler.transform(raw_X)\n",
        "        X_win = self._to_windows(scaled_X)\n",
        "\n",
        "        y_pred_s = self.model.predict(X_win, verbose=0)\n",
        "        y_pred_inv = self.y_scaler.inverse_transform(y_pred_s)\n",
        "\n",
        "        out_idx = df.index[self.window_size: self.window_size + y_pred_inv.shape[0]]\n",
        "        return pd.DataFrame(y_pred_inv, index=out_idx, columns=self.target_cols)\n",
        "\n",
        "    def predict_next_from_tail(self, df_tail: pd.DataFrame) -> np.ndarray:\n",
        "        df_tail = self._add_features(df_tail)\n",
        "\n",
        "        if len(df_tail) != self.window_size:\n",
        "            raise ValueError(f\"df_tail must have exactly window_size={self.window_size} rows\")\n",
        "\n",
        "        raw = df_tail[list(self.feature_cols)].to_numpy(dtype=float)\n",
        "        scaled = self.x_scaler.transform(raw)\n",
        "        X = np.expand_dims(scaled, axis=0)\n",
        "\n",
        "        y_pred_s = self.model.predict(X, verbose=0)[0]\n",
        "        return self.y_scaler.inverse_transform(y_pred_s.reshape(1, -1))[0]\n",
        "\n",
        "    def predict_future(self, df: pd.DataFrame, steps: int = 30) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Recursive multi-step forecast.\n",
        "        Each prediction is appended and used for the next input.\n",
        "        \"\"\"\n",
        "        df = self._add_features(df)\n",
        "\n",
        "        for c in self.feature_cols:\n",
        "            if c not in df.columns:\n",
        "                raise KeyError(f\"Missing feature '{c}' in new dataframe (expected {c})\")\n",
        "\n",
        "        df_work = df.copy()\n",
        "        preds = []\n",
        "\n",
        "        for _ in range(steps):\n",
        "            # Build input from last window\n",
        "            seq = df_work.tail(self.window_size)\n",
        "            X_in = seq[self.feature_cols].to_numpy(dtype=float)\n",
        "            X_in = self.x_scaler.transform(X_in).reshape(1, self.window_size, len(self.feature_cols))\n",
        "\n",
        "            # Predict next OHLCV\n",
        "            y_pred_s = self.model.predict(X_in, verbose=0)[0]\n",
        "            y_pred = self.y_scaler.inverse_transform(y_pred_s.reshape(1, -1))[0]\n",
        "\n",
        "            # Create new row (with predicted OHLCV)\n",
        "            next_row = {col: val for col, val in zip(self.target_cols, y_pred)}\n",
        "            next_row[\"Time\"] = df_work[\"Time\"].iloc[-1] + pd.Timedelta(minutes=1)\n",
        "\n",
        "            # --- IMPORTANT ---\n",
        "            # Keep the predicted OHLCV fixed, only add extra features\n",
        "            df_temp = pd.DataFrame([next_row])\n",
        "            df_temp = self._add_features(pd.concat([df_work, df_temp], ignore_index=True)).iloc[[-1]]\n",
        "\n",
        "            # Merge features into next_row without overwriting OHLCV\n",
        "            for c in self.feature_cols:\n",
        "                if c not in next_row and c in df_temp.columns:\n",
        "                    next_row[c] = df_temp[c].values[0]\n",
        "\n",
        "            # Append the enriched prediction\n",
        "            df_work = pd.concat([df_work, pd.DataFrame([next_row])], ignore_index=True)\n",
        "            preds.append(next_row)\n",
        "\n",
        "            print(\"Next row:\", next_row)\n",
        "\n",
        "        return pd.DataFrame(preds)\n",
        "\n",
        "\n",
        "\n",
        "from __future__ import annotations\n",
        "from dataclasses import dataclass\n",
        "from typing import Sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SequenceSplitter:\n",
        "    \"\"\"\n",
        "    Builds time-ordered Train/Val/Test windows.\n",
        "    Uses PROVIDED scalers (no refit) when resuming.\n",
        "    \"\"\"\n",
        "    config: SplitConfig\n",
        "\n",
        "    def split(\n",
        "        self,\n",
        "        df: pd.DataFrame,\n",
        "        feature_cols: Sequence[str],\n",
        "        target_cols: Sequence[str],\n",
        "        window_size: int,\n",
        "        ratios: Sequence[float],\n",
        "        x_scaler: object,\n",
        "        y_scaler: object,\n",
        "    ) -> DatasetSplit:\n",
        "        # enforce config (and validate), but keep the signature compatible\n",
        "        w = window_size\n",
        "        assert abs(sum(ratios) - 1.0) < 1e-9, \"ratios must sum to 1.0\"\n",
        "\n",
        "        for c in list(feature_cols) + list(target_cols):\n",
        "            if c not in df.columns:\n",
        "                raise KeyError(f\"Column '{c}' not in DataFrame. Available: {list(df.columns)}\")\n",
        "\n",
        "        raw_X = df[list(feature_cols)].to_numpy(dtype=float)\n",
        "        raw_y = df[list(target_cols)].to_numpy(dtype=float)\n",
        "\n",
        "        # transform with PROVIDED scalers (do not refit here)\n",
        "        scaled_X = x_scaler.transform(raw_X)\n",
        "        scaled_y = y_scaler.transform(raw_y)\n",
        "\n",
        "        N = len(df)\n",
        "        if N <= w:\n",
        "            raise ValueError(f\"Need N > window_size. Got N={N}, window_size={w}\")\n",
        "\n",
        "        # number of *target* positions we can produce\n",
        "        M = N - w\n",
        "\n",
        "        # NOTE: order is train, val, test  (not train, test, val)\n",
        "        n_train = int(M * ratios[0])\n",
        "        n_val   = int(M * ratios[1])\n",
        "        n_test  = M - n_train - n_val\n",
        "\n",
        "        def build(target_indices: range):\n",
        "            X, y, z, idx = [], [], [], []\n",
        "            for i in target_indices:\n",
        "                X.append(scaled_X[i - w:i, :])\n",
        "                y.append(scaled_y[i, :])\n",
        "                z.append(raw_y[i, :])   # unscaled targets (for inspection)\n",
        "                idx.append(i)\n",
        "            X = np.asarray(X, dtype=np.float32)\n",
        "            y = np.asarray(y, dtype=np.float32)\n",
        "            z = np.asarray(z, dtype=np.float32)\n",
        "            idx = np.asarray(idx, dtype=np.int64)\n",
        "            return X, y, z, idx\n",
        "\n",
        "        train_targets = range(w, w + n_train)\n",
        "        val_targets   = range(w + n_train, w + n_train + n_val)\n",
        "        test_targets  = range(w + n_train + n_val, w + M)\n",
        "\n",
        "        X_train, y_train, z_train, idx_train = build(train_targets)\n",
        "        X_val,   y_val,   z_val,   idx_val   = build(val_targets)\n",
        "        X_test,  y_test,  z_test,  idx_test  = build(test_targets)\n",
        "\n",
        "        scalers = ScalerBundle(x_scaler=x_scaler, y_scaler=y_scaler)\n",
        "        return DatasetSplit(\n",
        "            X_train, y_train, z_train, idx_train,\n",
        "            X_test, y_test, z_test, idx_test,\n",
        "            X_val, y_val, z_val, idx_val,\n",
        "            tuple(feature_cols), tuple(target_cols), w, scalers,\n",
        "        )\n",
        "\n",
        "from __future__ import annotations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Iterable\n",
        "import ta\n",
        "\n",
        "\n",
        "class CsvPreprocessor:\n",
        "    \"\"\"\n",
        "    Loads and cleans the Exness M1 CSV:\n",
        "    - parse Time to UTC\n",
        "    - sort by Time & reset index\n",
        "    - drop Spread/RealVolume (if present)\n",
        "    - add engineered features (OHLCV, returns, volatility, time, technicals, day-of-week)\n",
        "    - session assumed 01:05–23:54 UTC, Monday–Friday\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, drop_cols: Iterable[str] = (\"Spread\", \"RealVolume\")):\n",
        "        self.drop_cols = tuple(drop_cols)\n",
        "\n",
        "        # All engineered features (now 29 total, including day-of-week)\n",
        "        self.feature_cols = [\n",
        "            # Returns\n",
        "            \"Close_ret\", \"Open_ret\", \"High_ret\", \"Low_ret\",\n",
        "            # Volatility\n",
        "            \"Range\",\n",
        "            # Time features\n",
        "            \"minute_of_day\", \"slot5\", \"slot5_sin\", \"slot5_cos\",\n",
        "            \"minutes_from_open\", \"minutes_to_close\", \"percent_session_elapsed\",\n",
        "            \"is_open\", \"is_close\",\n",
        "            # Day of week\n",
        "            \"day_of_week\", \"dow_sin\", \"dow_cos\", \"is_monday\", \"is_friday\",\n",
        "            # Technical indicators\n",
        "            \"SMA10\", \"SMA20\", \"EMA10\", \"VWAP\",\n",
        "            \"RSI14\", \"MACD\", \"MACD_signal\", \"MACD_diff\",\n",
        "            \"Bollinger_high\", \"Bollinger_low\", \"Bollinger_mavg\",\n",
        "            \"ATR14\"\n",
        "        ]\n",
        "\n",
        "    def load(self, path: str) -> pd.DataFrame:\n",
        "        df = pd.read_csv(path)\n",
        "        empty_rows = df.isnull().all(axis=1)\n",
        "        if empty_rows.any():\n",
        "            print(\"Empty rows found at indices:\")\n",
        "            print(empty_rows[empty_rows].index)\n",
        "        else:\n",
        "            print(\"No empty rows found in the dataset.\")\n",
        "        return df\n",
        "\n",
        "    def preprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        df = df.copy()\n",
        "        # --- Time handling ---\n",
        "        if \"Time\" not in df.columns:\n",
        "            raise KeyError(\"Expected 'Time' column in CSV\")\n",
        "        df[\"Time\"] = pd.to_datetime(df[\"Time\"], utc=True)\n",
        "        df.sort_values(by=\"Time\", ascending=True, inplace=True)\n",
        "        df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "        # Drop extra cols if present\n",
        "        df = df.drop(columns=list(self.drop_cols), errors=\"ignore\")\n",
        "\n",
        "        # numeric columns (all except Time)\n",
        "        num_cols = df.columns.drop([\"Time\"]).tolist()\n",
        "        df[num_cols] = df[num_cols].replace({',': ''}, regex=True)\n",
        "        df[num_cols] = df[num_cols].astype(\"float64\")\n",
        "\n",
        "        # Add engineered features\n",
        "        df = self._add_features(df)\n",
        "\n",
        "        # Drop NaNs introduced by rolling indicators\n",
        "        df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def _add_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        # --- Returns ---\n",
        "        for col in [\"Close\", \"Open\", \"High\", \"Low\"]:\n",
        "            df[f\"{col}_ret\"] = df[col].pct_change()\n",
        "\n",
        "        # --- Volatility (Range) ---\n",
        "        df[\"Range\"] = df[\"High\"] - df[\"Low\"]\n",
        "\n",
        "        # --- Time features ---\n",
        "        df[\"minute_of_day\"] = df[\"Time\"].dt.hour * 60 + df[\"Time\"].dt.minute\n",
        "        df[\"slot5\"] = df[\"minute_of_day\"] // 5\n",
        "        df[\"slot5_sin\"] = np.sin(2 * np.pi * df[\"slot5\"] / 288)\n",
        "        df[\"slot5_cos\"] = np.cos(2 * np.pi * df[\"slot5\"] / 288)\n",
        "\n",
        "        # Define daily session boundaries (UTC 01:05 → 23:54)\n",
        "        session_open = 65  # 01:05 = 60 + 5\n",
        "        session_close = 1434  # 23:54 = 23*60 + 54\n",
        "\n",
        "        df[\"minutes_from_open\"] = df[\"minute_of_day\"] - session_open\n",
        "        df[\"minutes_to_close\"] = session_close - df[\"minute_of_day\"]\n",
        "        df[\"percent_session_elapsed\"] = (\n",
        "                df[\"minutes_from_open\"] / (session_close - session_open)\n",
        "        ).clip(0, 1)\n",
        "\n",
        "        # Flags\n",
        "        df[\"is_open\"] = (df[\"minute_of_day\"] == session_open).astype(int)\n",
        "        df[\"is_close\"] = (df[\"minute_of_day\"] == session_close).astype(int)\n",
        "\n",
        "        # --- Day-of-week features ---\n",
        "        df[\"day_of_week\"] = df[\"Time\"].dt.dayofweek  # 0=Mon … 4=Fri\n",
        "        df[\"dow_sin\"] = np.sin(2 * np.pi * df[\"day_of_week\"] / 5)\n",
        "        df[\"dow_cos\"] = np.cos(2 * np.pi * df[\"day_of_week\"] / 5)\n",
        "        df[\"is_monday\"] = (df[\"day_of_week\"] == 0).astype(int)\n",
        "        df[\"is_friday\"] = (df[\"day_of_week\"] == 4).astype(int)\n",
        "\n",
        "        # --- Technical Indicators ---\n",
        "        df[\"SMA10\"] = df[\"Close\"].rolling(10).mean()\n",
        "        df[\"SMA20\"] = df[\"Close\"].rolling(20).mean()\n",
        "        df[\"EMA10\"] = df[\"Close\"].ewm(span=10, adjust=False).mean()\n",
        "        df[\"VWAP\"] = (df[\"Close\"] * df[\"TickVolume\"]).cumsum() / df[\"TickVolume\"].cumsum()\n",
        "\n",
        "        # RSI (14)\n",
        "        df[\"RSI14\"] = ta.momentum.RSIIndicator(df[\"Close\"], window=14).rsi()\n",
        "\n",
        "        # MACD (12, 26, 9)\n",
        "        macd = ta.trend.MACD(close=df[\"Close\"])\n",
        "        df[\"MACD\"] = macd.macd()\n",
        "        df[\"MACD_signal\"] = macd.macd_signal()\n",
        "        df[\"MACD_diff\"] = macd.macd_diff()\n",
        "\n",
        "        # Bollinger Bands (20, 2)\n",
        "        boll = ta.volatility.BollingerBands(close=df[\"Close\"], window=20, window_dev=2)\n",
        "        df[\"Bollinger_high\"] = boll.bollinger_hband()\n",
        "        df[\"Bollinger_low\"] = boll.bollinger_lband()\n",
        "        df[\"Bollinger_mavg\"] = boll.bollinger_mavg()\n",
        "\n",
        "        # ATR (14)\n",
        "        atr = ta.volatility.AverageTrueRange(\n",
        "            high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"], window=14\n",
        "        )\n",
        "        df[\"ATR14\"] = atr.average_true_range()\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "FyIg1uP7HWWS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model_predict()"
      ],
      "metadata": {
        "id": "Jki7BzXgHWcG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}